2024-12-23 01:52:33,203 WARNING - Could not import pandas. Holidays will not be considered.
2024-12-23 01:52:33,210 INFO - Loaded executor: SequentialExecutor
2024-12-23 01:52:33,275 INFO - Starting the scheduler
2024-12-23 01:52:33,277 INFO - Processing each file at most -1 times
2024-12-23 01:52:33,290 INFO - Launched DagFileProcessorManager with pid: 26960
2024-12-23 01:52:33,295 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 01:52:33,302 INFO - Configured default timezone UTC
2024-12-23 01:57:34,122 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:02:34,468 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:07:34,830 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:12:35,097 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:17:35,363 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:22:35,640 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:27:35,818 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:32:36,300 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:37:36,568 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:42:36,833 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:47:36,956 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:52:36,995 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:53:56,741 INFO - Loaded executor: SequentialExecutor
2024-12-23 02:53:56,799 INFO - Starting the scheduler
2024-12-23 02:53:56,801 INFO - Processing each file at most -1 times
2024-12-23 02:53:56,811 INFO - Launched DagFileProcessorManager with pid: 36449
2024-12-23 02:53:56,814 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 02:53:56,819 INFO - Configured default timezone UTC
2024-12-23 02:58:57,007 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:03:57,193 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:08:57,481 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:13:57,869 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:18:58,157 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:23:58,340 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:28:58,659 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:33:58,934 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:38:59,203 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:43:59,473 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:48:59,664 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:53:59,725 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 03:58:59,990 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:04:00,256 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:05:09,630 INFO - Setting next_dagrun for weather_et_pipeline to 2024-12-22 00:00:00+00:00, run_after=2024-12-23 00:00:00+00:00
2024-12-23 04:05:09,728 INFO - 1 tasks up for execution:
	<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:05:09,729 INFO - DAG weather_et_pipeline has 0/16 running and queued tasks
2024-12-23 04:05:09,730 INFO - Setting the following tasks to queued state:
	<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:05:09,737 INFO - Trying to enqueue tasks: [<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2024-12-23 04:05:09,738 INFO - Sending TaskInstanceKey(dag_id='weather_et_pipeline', task_id='extract_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2024-12-23 04:05:09,739 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'extract_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:05:09,748 INFO - Executing command: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'extract_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:05:13,991 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='weather_et_pipeline', task_id='extract_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-12-23 04:05:14,003 INFO - TaskInstance Finished: dag_id=weather_et_pipeline, task_id=extract_weather_data, run_id=scheduled__2024-12-21T00:00:00+00:00, map_index=-1, run_start_date=2024-12-22 22:05:13.046435+00:00, run_end_date=2024-12-22 22:05:13.247140+00:00, run_duration=0.200705, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=7, pool=default_pool, queue=default, priority_weight=3, operator=_PythonDecoratedOperator, queued_dttm=2024-12-22 22:05:09.732136+00:00, queued_by_job_id=3, pid=48348
2024-12-23 04:05:15,590 ERROR - Marking run <DagRun weather_et_pipeline @ 2024-12-21 00:00:00+00:00: scheduled__2024-12-21T00:00:00+00:00, state:running, queued_at: 2024-12-22 22:05:09.611388+00:00. externally triggered: False> failed
2024-12-23 04:05:15,591 INFO - DagRun Finished: dag_id=weather_et_pipeline, execution_date=2024-12-21 00:00:00+00:00, run_id=scheduled__2024-12-21T00:00:00+00:00, run_start_date=2024-12-22 22:05:09.646244+00:00, run_end_date=2024-12-22 22:05:15.591226+00:00, run_duration=5.944982, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-21 00:00:00+00:00, data_interval_end=2024-12-22 00:00:00+00:00, dag_hash=7d14fdb01be81536b0b694497fd46298
2024-12-23 04:05:15,599 INFO - Setting next_dagrun for weather_et_pipeline to 2024-12-22 00:00:00+00:00, run_after=2024-12-23 00:00:00+00:00
2024-12-23 04:09:00,544 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:14:00,605 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:19:00,983 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:24:01,070 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:29:01,340 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:34:01,613 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:39:01,896 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:44:02,264 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:44:46,983 INFO - Setting next_dagrun for weather_et_pipeline to 2024-12-22 00:00:00+00:00, run_after=2024-12-23 00:00:00+00:00
2024-12-23 04:44:47,038 INFO - 1 tasks up for execution:
	<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:44:47,038 INFO - DAG weather_et_pipeline has 0/16 running and queued tasks
2024-12-23 04:44:47,039 INFO - Setting the following tasks to queued state:
	<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:44:47,041 INFO - Trying to enqueue tasks: [<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2024-12-23 04:44:47,042 INFO - Sending TaskInstanceKey(dag_id='weather_et_pipeline', task_id='extract_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 3 and queue default
2024-12-23 04:44:47,043 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'extract_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:44:47,047 INFO - Executing command: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'extract_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:44:52,875 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='weather_et_pipeline', task_id='extract_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-12-23 04:44:52,882 INFO - TaskInstance Finished: dag_id=weather_et_pipeline, task_id=extract_weather_data, run_id=scheduled__2024-12-21T00:00:00+00:00, map_index=-1, run_start_date=2024-12-22 22:44:50.738534+00:00, run_end_date=2024-12-22 22:44:52.093080+00:00, run_duration=1.354546, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=9, pool=default_pool, queue=default, priority_weight=3, operator=_PythonDecoratedOperator, queued_dttm=2024-12-22 22:44:47.040587+00:00, queued_by_job_id=3, pid=53038
2024-12-23 04:44:53,102 INFO - 1 tasks up for execution:
	<TaskInstance: weather_et_pipeline.transform_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:44:53,103 INFO - DAG weather_et_pipeline has 0/16 running and queued tasks
2024-12-23 04:44:53,103 INFO - Setting the following tasks to queued state:
	<TaskInstance: weather_et_pipeline.transform_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:44:53,106 INFO - Trying to enqueue tasks: [<TaskInstance: weather_et_pipeline.transform_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2024-12-23 04:44:53,106 INFO - Sending TaskInstanceKey(dag_id='weather_et_pipeline', task_id='transform_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 2 and queue default
2024-12-23 04:44:53,107 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'transform_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:44:53,111 INFO - Executing command: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'transform_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:44:57,528 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='weather_et_pipeline', task_id='transform_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-12-23 04:44:57,537 INFO - TaskInstance Finished: dag_id=weather_et_pipeline, task_id=transform_data, run_id=scheduled__2024-12-21T00:00:00+00:00, map_index=-1, run_start_date=2024-12-22 22:44:56.561786+00:00, run_end_date=2024-12-22 22:44:56.762964+00:00, run_duration=0.201178, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=10, pool=default_pool, queue=default, priority_weight=2, operator=_PythonDecoratedOperator, queued_dttm=2024-12-22 22:44:53.104625+00:00, queued_by_job_id=3, pid=53050
2024-12-23 04:44:57,716 INFO - 1 tasks up for execution:
	<TaskInstance: weather_et_pipeline.load_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:44:57,716 INFO - DAG weather_et_pipeline has 0/16 running and queued tasks
2024-12-23 04:44:57,717 INFO - Setting the following tasks to queued state:
	<TaskInstance: weather_et_pipeline.load_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:44:57,720 INFO - Trying to enqueue tasks: [<TaskInstance: weather_et_pipeline.load_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2024-12-23 04:44:57,721 INFO - Sending TaskInstanceKey(dag_id='weather_et_pipeline', task_id='load_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1) to SequentialExecutor with priority 1 and queue default
2024-12-23 04:44:57,721 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'load_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:44:57,725 INFO - Executing command: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'load_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:45:02,733 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='weather_et_pipeline', task_id='load_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=1, map_index=-1)
2024-12-23 04:45:02,742 INFO - TaskInstance Finished: dag_id=weather_et_pipeline, task_id=load_weather_data, run_id=scheduled__2024-12-21T00:00:00+00:00, map_index=-1, run_start_date=2024-12-22 22:45:01.150725+00:00, run_end_date=2024-12-22 22:45:02.019582+00:00, run_duration=0.868857, state=failed, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=1, max_tries=0, job_id=11, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2024-12-22 22:44:57.718761+00:00, queued_by_job_id=3, pid=53062
2024-12-23 04:45:02,932 ERROR - Marking run <DagRun weather_et_pipeline @ 2024-12-21 00:00:00+00:00: scheduled__2024-12-21T00:00:00+00:00, state:running, queued_at: 2024-12-22 22:44:46.973918+00:00. externally triggered: False> failed
2024-12-23 04:45:02,933 INFO - DagRun Finished: dag_id=weather_et_pipeline, execution_date=2024-12-21 00:00:00+00:00, run_id=scheduled__2024-12-21T00:00:00+00:00, run_start_date=2024-12-22 22:44:47.003642+00:00, run_end_date=2024-12-22 22:45:02.933376+00:00, run_duration=15.929734, state=failed, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-21 00:00:00+00:00, data_interval_end=2024-12-22 00:00:00+00:00, dag_hash=7d14fdb01be81536b0b694497fd46298
2024-12-23 04:45:02,940 INFO - Setting next_dagrun for weather_et_pipeline to 2024-12-22 00:00:00+00:00, run_after=2024-12-23 00:00:00+00:00
2024-12-23 04:48:43,081 INFO - 1 tasks up for execution:
	<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:48:43,081 INFO - DAG weather_et_pipeline has 0/16 running and queued tasks
2024-12-23 04:48:43,082 INFO - Setting the following tasks to queued state:
	<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:48:43,084 INFO - Trying to enqueue tasks: [<TaskInstance: weather_et_pipeline.extract_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2024-12-23 04:48:43,085 INFO - Sending TaskInstanceKey(dag_id='weather_et_pipeline', task_id='extract_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 3 and queue default
2024-12-23 04:48:43,086 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'extract_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:48:43,090 INFO - Executing command: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'extract_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:48:48,628 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='weather_et_pipeline', task_id='extract_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=2, map_index=-1)
2024-12-23 04:48:48,636 INFO - TaskInstance Finished: dag_id=weather_et_pipeline, task_id=extract_weather_data, run_id=scheduled__2024-12-21T00:00:00+00:00, map_index=-1, run_start_date=2024-12-22 22:48:46.554002+00:00, run_end_date=2024-12-22 22:48:47.866079+00:00, run_duration=1.312077, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=12, pool=default_pool, queue=default, priority_weight=3, operator=_PythonDecoratedOperator, queued_dttm=2024-12-22 22:48:43.083311+00:00, queued_by_job_id=3, pid=53345
2024-12-23 04:48:48,973 INFO - 1 tasks up for execution:
	<TaskInstance: weather_et_pipeline.transform_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:48:48,973 INFO - DAG weather_et_pipeline has 0/16 running and queued tasks
2024-12-23 04:48:48,974 INFO - Setting the following tasks to queued state:
	<TaskInstance: weather_et_pipeline.transform_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:48:48,977 INFO - Trying to enqueue tasks: [<TaskInstance: weather_et_pipeline.transform_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2024-12-23 04:48:48,978 INFO - Sending TaskInstanceKey(dag_id='weather_et_pipeline', task_id='transform_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 2 and queue default
2024-12-23 04:48:48,978 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'transform_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:48:48,986 INFO - Executing command: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'transform_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:48:53,380 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='weather_et_pipeline', task_id='transform_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=2, map_index=-1)
2024-12-23 04:48:53,389 INFO - TaskInstance Finished: dag_id=weather_et_pipeline, task_id=transform_data, run_id=scheduled__2024-12-21T00:00:00+00:00, map_index=-1, run_start_date=2024-12-22 22:48:52.386088+00:00, run_end_date=2024-12-22 22:48:52.615893+00:00, run_duration=0.229805, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=13, pool=default_pool, queue=default, priority_weight=2, operator=_PythonDecoratedOperator, queued_dttm=2024-12-22 22:48:48.975854+00:00, queued_by_job_id=3, pid=53358
2024-12-23 04:48:53,674 INFO - 1 tasks up for execution:
	<TaskInstance: weather_et_pipeline.load_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:48:53,675 INFO - DAG weather_et_pipeline has 0/16 running and queued tasks
2024-12-23 04:48:53,675 INFO - Setting the following tasks to queued state:
	<TaskInstance: weather_et_pipeline.load_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>
2024-12-23 04:48:53,678 INFO - Trying to enqueue tasks: [<TaskInstance: weather_et_pipeline.load_weather_data scheduled__2024-12-21T00:00:00+00:00 [scheduled]>] for executor: SequentialExecutor(parallelism=32)
2024-12-23 04:48:53,679 INFO - Sending TaskInstanceKey(dag_id='weather_et_pipeline', task_id='load_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=2, map_index=-1) to SequentialExecutor with priority 1 and queue default
2024-12-23 04:48:53,680 INFO - Adding to queue: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'load_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:48:53,683 INFO - Executing command: ['airflow', 'tasks', 'run', 'weather_et_pipeline', 'load_weather_data', 'scheduled__2024-12-21T00:00:00+00:00', '--local', '--subdir', 'DAGS_FOLDER/weather_etl_pipeline.py']
2024-12-23 04:48:58,823 INFO - Received executor event with state success for task instance TaskInstanceKey(dag_id='weather_et_pipeline', task_id='load_weather_data', run_id='scheduled__2024-12-21T00:00:00+00:00', try_number=2, map_index=-1)
2024-12-23 04:48:58,831 INFO - TaskInstance Finished: dag_id=weather_et_pipeline, task_id=load_weather_data, run_id=scheduled__2024-12-21T00:00:00+00:00, map_index=-1, run_start_date=2024-12-22 22:48:57.124338+00:00, run_end_date=2024-12-22 22:48:58.077534+00:00, run_duration=0.953196, state=success, executor=SequentialExecutor(parallelism=32), executor_state=success, try_number=2, max_tries=1, job_id=14, pool=default_pool, queue=default, priority_weight=1, operator=_PythonDecoratedOperator, queued_dttm=2024-12-22 22:48:53.676969+00:00, queued_by_job_id=3, pid=53370
2024-12-23 04:48:59,129 INFO - Marking run <DagRun weather_et_pipeline @ 2024-12-21 00:00:00+00:00: scheduled__2024-12-21T00:00:00+00:00, state:running, queued_at: 2024-12-22 22:48:42.626012+00:00. externally triggered: False> successful
2024-12-23 04:48:59,130 INFO - DagRun Finished: dag_id=weather_et_pipeline, execution_date=2024-12-21 00:00:00+00:00, run_id=scheduled__2024-12-21T00:00:00+00:00, run_start_date=2024-12-22 22:48:43.038574+00:00, run_end_date=2024-12-22 22:48:59.130754+00:00, run_duration=16.09218, state=success, external_trigger=False, run_type=scheduled, data_interval_start=2024-12-21 00:00:00+00:00, data_interval_end=2024-12-22 00:00:00+00:00, dag_hash=7d14fdb01be81536b0b694497fd46298
2024-12-23 04:48:59,137 INFO - Setting next_dagrun for weather_et_pipeline to 2024-12-22 00:00:00+00:00, run_after=2024-12-23 00:00:00+00:00
2024-12-23 04:49:02,530 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:54:02,744 INFO - Adopting or resetting orphaned tasks for active dag runs
2024-12-23 04:59:03,013 INFO - Adopting or resetting orphaned tasks for active dag runs
